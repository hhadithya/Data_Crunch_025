{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten, MaxPooling1D, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "targets = ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction_cos','Wind_Direction_sin']\n",
    "features = ['kingdom_group', 'DayOfWeek_sin', 'DayOfWeek_cos', 'DayOfYear_sin',\n",
    "            'DayOfYear_cos', 'Month_sin', 'Month_cos', 'Quarter_sin', 'Quarter_cos']\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for kingdom in data['kingdom_group'].unique():\n",
    "        kingdom_data = data[data['kingdom_group'] == kingdom]\n",
    "        kingdom_data = kingdom_data.sort_values('Date')\n",
    "        X = kingdom_data[features].values\n",
    "        y = kingdom_data[targets].values\n",
    "        for i in range(len(X) - seq_length):\n",
    "            xs.append(X[i:(i + seq_length)])\n",
    "            ys.append(y[i + seq_length])\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "seq_length = 30\n",
    "\n",
    "train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
    "test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "train_df[features] = feature_scaler.fit_transform(train_df[features])\n",
    "test_df[features] = feature_scaler.transform(test_df[features])\n",
    "\n",
    "target_scaler = StandardScaler()\n",
    "train_df[targets] = target_scaler.fit_transform(train_df[targets])\n",
    "\n",
    "X_train, y_train = create_sequences(train_df, seq_length)\n",
    "\n",
    "def build_cnn_model(input_shape, output_dim):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.2),\n",
    "        Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(output_dim)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mse'\n",
    "    )\n",
    "    return model\n",
    "\n",
    "input_shape = (seq_length, len(features))\n",
    "model = build_cnn_model(input_shape, len(targets))\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "def predict_for_test(model, test_df, train_df, seq_length):\n",
    "    predictions = pd.DataFrame()\n",
    "\n",
    "    for kingdom in test_df['kingdom_group'].unique():\n",
    "        kingdom_train = train_df[train_df['kingdom_group'] == kingdom].sort_values('Date').tail(seq_length)\n",
    "        kingdom_test = test_df[test_df['kingdom_group'] == kingdom].sort_values('Date')\n",
    "        sequence = kingdom_train[features].values.astype(np.float32)\n",
    "\n",
    "        kingdom_preds = []\n",
    "        for _, row in kingdom_test.iterrows():\n",
    "            X = np.array([sequence[-seq_length:]]).astype(np.float32)\n",
    "\n",
    "            if X.shape[1:] != (seq_length, len(features)):\n",
    "                if X.shape[1] < seq_length:\n",
    "                    padding = np.zeros((1, seq_length - X.shape[1], X.shape[2]), dtype=np.float32)\n",
    "                    X = np.concatenate([padding, X], axis=1)\n",
    "\n",
    "            pred = model.predict(X, verbose=0)[0]\n",
    "            kingdom_preds.append(pred)\n",
    "            new_features = row[features].values.reshape(1, -1).astype(np.float32)\n",
    "            sequence = np.vstack([sequence, new_features])\n",
    "\n",
    "        kingdom_df = kingdom_test.copy()\n",
    "\n",
    "        if kingdom_preds:\n",
    "            kingdom_pred_array = np.array(kingdom_preds)\n",
    "\n",
    "            for i, target in enumerate(targets):\n",
    "                kingdom_df[target] = kingdom_pred_array[:, i]\n",
    "\n",
    "            predictions = pd.concat([predictions, kingdom_df])\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def fix_datatypes(df, columns):\n",
    "    for col in columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            try:\n",
    "                df[col] = df[col].astype(float)\n",
    "            except ValueError:\n",
    "                print(f\"Could not convert {col} to float.\")\n",
    "    return df\n",
    "\n",
    "train_df = fix_datatypes(train_df, features + targets)\n",
    "test_df = fix_datatypes(test_df, features)\n",
    "\n",
    "predictions_df = predict_for_test(model, test_df, train_df, seq_length)\n",
    "\n",
    "predictions_array = predictions_df[targets].values\n",
    "original_scale_predictions = target_scaler.inverse_transform(predictions_array)\n",
    "\n",
    "for i, target in enumerate(targets):\n",
    "    predictions_df[target] = original_scale_predictions[:, i]\n",
    "\n",
    "val_size = int(0.1 * len(train_df))\n",
    "val_df = train_df.tail(val_size)\n",
    "train_df_reduced = train_df.iloc[:-val_size]\n",
    "\n",
    "X_train_final, y_train_final = create_sequences(train_df_reduced, seq_length)\n",
    "val_predictions = predict_for_test(model, val_df, train_df_reduced, seq_length)\n",
    "\n",
    "metrics = {}\n",
    "for i, target in enumerate(targets):\n",
    "    actual = target_scaler.inverse_transform(val_df[targets].values)[:, i]\n",
    "    predicted = target_scaler.inverse_transform(val_predictions[targets].values)[:, i]\n",
    "\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = sqrt(mse)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    mape = np.mean(np.abs((actual - predicted) / np.maximum(np.abs(actual), 1e-10))) * 100\n",
    "\n",
    "    metrics[target] = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'RÂ²': r2,\n",
    "        'MAPE (%)': mape\n",
    "    }\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "avg_metrics = metrics_df.mean(axis=1)\n",
    "\n",
    "for target in targets:\n",
    "    test_df[target] = predictions_df[target]"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
